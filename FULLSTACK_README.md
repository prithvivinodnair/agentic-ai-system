# üöÄ Full-Stack Agentic AI System

## Complete Production-Ready Application

You now have a **full-stack multi-agent AI application** with:

- ‚úÖ **Backend:** FastAPI + Python multi-agent system
- ‚úÖ **Frontend:** Next.js + React + TypeScript + Tailwind CSS
- ‚úÖ **FREE to run:** Google Gemini API
- ‚úÖ **Beautiful UI:** Modern, responsive dashboard
- ‚úÖ **Real-time updates:** Live progress tracking
- ‚úÖ **Production-ready:** Clean code, error handling, documentation

---

## üéØ What You Built

### Backend (Python + FastAPI)
- 5 specialized AI agents
- RESTful API with auto-generated docs
- Async workflow execution
- Background task processing
- CORS-enabled for frontend

### Frontend (Next.js + React)
- Modern, responsive dashboard
- Real-time workflow tracking
- Beautiful result visualization
- Dark mode support
- Mobile-friendly design

---

## ‚ö° Quick Start

### Option 1: Automated Startup (Windows)

Double-click: **`start_fullstack.bat`**

This will:
1. Start the backend API
2. Start the frontend dev server
3. Open your browser automatically

### Option 2: Manual Startup

**Terminal 1 - Backend:**
```bash
cd "c:\Users\Prithvi Nair\OneDrive\Desktop\Agentic AI"
.venv\Scripts\Activate.ps1
python api_server.py
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm install  # First time only
npm run dev
```

**Browser:**
Go to: http://localhost:3000

---

## üì∏ Screenshots

### Dashboard
![Dashboard showing scenario selection and beautiful UI]

### Running Workflow
![Real-time progress with animated status indicators]

### Results
![Beautiful cards showing decision, confidence, next steps, and risks]

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Frontend (Next.js)              ‚îÇ
‚îÇ    http://localhost:3000                ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  ‚Ä¢ Scenario Selection                   ‚îÇ
‚îÇ  ‚Ä¢ Workflow Execution                   ‚îÇ
‚îÇ  ‚Ä¢ Real-time Progress                   ‚îÇ
‚îÇ  ‚Ä¢ Results Visualization                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îÇ HTTP/REST API
              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Backend API (FastAPI)              ‚îÇ
‚îÇ    http://localhost:8000                ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  ‚Ä¢ RESTful Endpoints                    ‚îÇ
‚îÇ  ‚Ä¢ Background Tasks                     ‚îÇ
‚îÇ  ‚Ä¢ Workflow Management                  ‚îÇ
‚îÇ  ‚Ä¢ Auto-generated Docs                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Multi-Agent Orchestrator             ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ Data     ‚îÇ‚Üí ‚îÇ Analysis ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ Ingestion‚îÇ  ‚îÇ Agent    ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ        ‚Üì              ‚Üì                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇReasoning ‚îÇ‚Üí ‚îÇ Decision ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ Agent    ‚îÇ  ‚îÇ Agent    ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ        ‚Üì                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ  ‚îÇExecution ‚îÇ                          ‚îÇ
‚îÇ  ‚îÇ Agent    ‚îÇ                          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       LLM Provider (Gemini)             ‚îÇ
‚îÇ         FREE API                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìã API Endpoints

### GET /
Health check

### GET /scenarios
List available scenarios
```json
{
  "scenarios": [
    {
      "id": "emergency",
      "name": "Emergency Resource Allocation",
      "description": "Hurricane disaster response",
      "category": "Emergency Management"
    }
  ]
}
```

### POST /workflow/run
Start a workflow
```json
{
  "scenario_type": "emergency"
}
```

Response:
```json
{
  "workflow_id": "uuid-here",
  "status": "running",
  "message": "Workflow started successfully"
}
```

### GET /workflow/{workflow_id}
Get workflow status and results
```json
{
  "workflow_id": "uuid",
  "status": "completed",
  "progress": 100,
  "results": { ... }
}
```

### Full API Documentation
http://localhost:8000/docs (Interactive Swagger UI)

---

## üé® Features

### Real-Time Progress
- Live status updates every 2 seconds
- Progress bar with current stage
- Animated status indicators

### Beautiful Results Display
- Gradient cards for key decisions
- Color-coded confidence levels
- Organized next steps with numbering
- Risk identification with icons
- Responsive grid layout

### User Experience
- Smooth transitions and animations
- Loading states
- Error handling
- Dark mode support
- Mobile responsive

---

## üîß Technology Stack

### Frontend
| Technology | Purpose | Why |
|-----------|---------|-----|
| Next.js 14 | React Framework | SSR, routing, optimization |
| TypeScript | Type Safety | Catch errors before runtime |
| Tailwind CSS | Styling | Rapid development, consistent design |
| Axios | HTTP Client | Simple API calls |
| Lucide React | Icons | Beautiful, consistent icons |

### Backend
| Technology | Purpose | Why |
|-----------|---------|-----|
| FastAPI | API Framework | Auto docs, async, type hints |
| Uvicorn | ASGI Server | High performance |
| Pydantic | Data Validation | Type-safe request/response |
| Python AsyncIO | Concurrency | Non-blocking operations |

### AI/ML
| Technology | Purpose | Why |
|-----------|---------|-----|
| Google Gemini | LLM | FREE, high quality |
| LangChain | Agent Framework | Structured AI workflows |
| Multi-Agent System | Decision Making | Specialized, modular agents |

---

## üí° Use Cases

Perfect for demonstrating:

1. **Full-Stack Development**
   - Frontend + Backend integration
   - RESTful API design
   - Real-time data updates

2. **AI/ML Engineering**
   - Multi-agent systems
   - LLM integration
   - Prompt engineering

3. **Data Engineering**
   - Unstructured data processing
   - Pipeline orchestration
   - Async workflows

4. **Product Development**
   - User interface design
   - User experience
   - Production deployment

---

## üìö Documentation

- **[FRONTEND_SETUP.md](FRONTEND_SETUP.md)** - Complete frontend guide
- **[FREE_SETUP.md](FREE_SETUP.md)** - Free LLM setup
- **[QUICKSTART.md](QUICKSTART.md)** - 5-minute quickstart
- **[PROJECT_SUMMARY.md](PROJECT_SUMMARY.md)** - Interview prep
- **[README.md](README.md)** - Main documentation

---

## üé§ Interview Demo Script

### 1. Introduction (30 seconds)
> "I built a full-stack multi-agent AI system for national-scale operational decision-making. The frontend is built with Next.js and TypeScript, the backend uses FastAPI with Python, and it integrates with Google's Gemini AI for intelligent decision-making."

### 2. Architecture Overview (1 minute)
> "The system uses a multi-agent architecture. Five specialized agents handle different aspects: data ingestion, analysis, reasoning, decision-making, and execution planning. They're coordinated by an orchestrator and exposed through a RESTful API."

*Show architecture diagram*

### 3. Live Demo (2-3 minutes)
> "Let me show you how it works."

1. Open http://localhost:3000
2. Select "Emergency Resource Allocation"
3. Click "Run Analysis"
4. Show real-time progress
5. Explain results as they appear

### 4. Technical Deep Dive (2 minutes)
> "On the frontend, I'm using Next.js with TypeScript and Tailwind CSS. The UI polls the backend every 2 seconds for updates. On the backend, FastAPI runs the workflow in a background task, so the API responds immediately."

*Show code: `api_server.py` and `frontend/app/page.tsx`*

### 5. Unique Features (1 minute)
> "What makes this interesting is the provider-agnostic LLM client. It works with OpenAI, Gemini, or local models via Ollama. I'm using Gemini's free tier for development, which demonstrates cost-conscious architecture."

### 6. Scalability (30 seconds)
> "To scale this, I'd add a database like PostgreSQL, implement caching with Redis, deploy the frontend to Vercel and backend to AWS Lambda or GCP Cloud Run, and add monitoring with Sentry."

**Total: 7-8 minutes**

---

## üöÄ Deployment

### Frontend (Vercel - FREE)

```bash
cd frontend
vercel deploy
```

Your frontend is live!

### Backend (Railway/Render/Heroku)

**Railway:**
1. Push to GitHub
2. Connect repository
3. Deploy automatically

**Environment Variables:**
```
LLM_PROVIDER=gemini
GOOGLE_API_KEY=your-key
```

---

## üìä For Your Resume

### Project Title
**Full-Stack Multi-Agent AI System for Operational Decision-Making**

### Description
*Built a production-ready full-stack application combining Next.js frontend with FastAPI backend, featuring a multi-agent GenAI system for automated decision-making. Implements real-time progress tracking, beautiful data visualization, and provider-agnostic LLM integration (OpenAI/Gemini). Includes RESTful API with auto-generated documentation, async workflow execution, and comprehensive error handling.*

### Technologies
**Frontend:** Next.js 14, React, TypeScript, Tailwind CSS, Axios
**Backend:** Python, FastAPI, Pydantic, Uvicorn, AsyncIO
**AI/ML:** LangChain, OpenAI/Gemini APIs, Multi-Agent Systems
**Tools:** Git, npm, pip, REST APIs

### Key Features
- Multi-agent AI architecture with 5 specialized agents
- Real-time workflow progress tracking
- Responsive web interface with dark mode
- RESTful API with Swagger documentation
- Background task processing
- Provider-agnostic LLM integration
- Production-ready error handling

---

## üéØ Next Steps

### Immediate (Today)
- [x] Run the full stack
- [ ] Try both scenarios
- [ ] Explore the API docs
- [ ] Customize the UI colors

### This Week
- [ ] Add export to PDF
- [ ] Add charts with Recharts
- [ ] Deploy frontend to Vercel
- [ ] Add your own custom scenario

### This Month
- [ ] Add user authentication
- [ ] Implement database storage
- [ ] Add workflow comparison
- [ ] Create mobile app version

---

## ‚ù§Ô∏è What You've Accomplished

You now have a **portfolio-quality full-stack AI application** that demonstrates:

‚úÖ Modern frontend development (Next.js, React, TypeScript)
‚úÖ Backend API design (FastAPI, RESTful, async)
‚úÖ AI/ML integration (LLMs, multi-agent systems)
‚úÖ Full-stack integration (Frontend ‚Üî API ‚Üî AI)
‚úÖ Production practices (error handling, docs, deployment-ready)
‚úÖ Cost consciousness (FREE to run!)
‚úÖ Professional documentation

**This is interview gold!** üèÜ

---

## üÜò Need Help?

### Quick Links
- Backend API Docs: http://localhost:8000/docs
- Frontend: http://localhost:3000
- [FRONTEND_SETUP.md](FRONTEND_SETUP.md) - Detailed setup
- [TROUBLESHOOTING.md](TROUBLESHOOTING.md) - Common issues

### Common Issues

**Port conflicts:**
```bash
# Windows
netstat -ano | findstr :3000
taskkill /PID <PID> /F
```

**Cannot connect:**
- Check both servers are running
- Verify `.env` has API key
- Check firewall settings

---

## üéâ You're Ready!

Everything is set up and ready to go. Just run:

```bash
start_fullstack.bat
```

Or manually start both servers and enjoy your full-stack AI application!

**Good luck with your interviews and demos!** üöÄ

---

Built with ‚ù§Ô∏è by Prithvi Nair
